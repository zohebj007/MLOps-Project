{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0d7ac4-be1f-481d-915b-42b19ec390f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "/opt/conda/lib/python3.12/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:ap-south-1:329599621181:pipeline/testing-1/execution/lr7i9qksuvkz', sagemaker_session=<sagemaker.workflow.pipeline_context.PipelineSession object at 0x7f87551ae780>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################  imports  ###################################\n",
    "from sagemaker import Session\n",
    "import sagemaker\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "import boto3\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "from sagemaker.workflow.steps import ProcessingStep, CreateModelStep\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "\n",
    "###################  parameters #####################\n",
    "bucket='main-sagemaker-ml-healthcare'\n",
    "prefix = 'mlops'\n",
    "input_source = f\"s3://{bucket}/{prefix}/diabetes.csv\"\n",
    "train_path = f\"s3://{bucket}/{prefix}/train\"\n",
    "test_path = f\"s3://{bucket}/{prefix}/test\"\n",
    "val_path = f\"s3://{bucket}/{prefix}/val\"\n",
    "model_output_uri = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "train_data_uri = train_path\n",
    "test_data_uri = test_path\n",
    "train_input = TrainingInput(s3_data=train_data_uri, content_type='text/csv')\n",
    "evaluation_output_uri = f\"s3://{bucket}/output/evaluation\"\n",
    "\n",
    "################# important for pipeline #####################\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "########### preprocessing of data ##################\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1, \n",
    "    base_job_name='diabetes-main'\n",
    ")\n",
    "\n",
    "# Define processing step\n",
    "processing_step = ProcessingStep(\n",
    "    name='PreprocessingStep',\n",
    "    processor=sklearn_processor,\n",
    "    code='preprocess.py',  # Path to your preprocessing script\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_source, \n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "            s3_input_mode=\"File\",\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\",\n",
    "            \n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train_data\", \n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=train_path,\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test_data\", \n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            destination=test_path,\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"val_data\", \n",
    "            source=\"/opt/ml/processing/output/validation\",\n",
    "            destination=val_path,\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "########  train step ###########\n",
    "\n",
    "estimator = SKLearn(entry_point='train.py',\n",
    "                    framework_version=\"0.23-1\",\n",
    "                    py_version='py3',\n",
    "                    instance_type='ml.m5.xlarge',\n",
    "                    role=role,\n",
    "                    output_path=model_output_uri,\n",
    "                    base_job_name='sklearn-iris',\n",
    "                    hyperparameters={'n_estimators': 50, 'max_depth': 5})\n",
    "# Define the input data for training and testing\n",
    "train_step = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"training\": train_input,\n",
    "    },\n",
    ")\n",
    "\n",
    "####### eval and register model and check the condition ######\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=\"ap-south-1\",\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "\n",
    "##### train artifacts ######\n",
    "model_artifact_path = train_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "########\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "# Initialize the ScriptProcessor\n",
    "evaluation_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    role=role,  # Replace with your actual role ARN\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "# Define the processing step for evaluation\n",
    "evaluation_step = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=model_artifact_path, destination=\"/opt/ml/processing/model\"),\n",
    "        ProcessingInput(source=test_path, destination=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/output\", destination=evaluation_output_uri),\n",
    "    ],\n",
    "    code=\"eval.py\",\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "# Define ModelMetrics for registration (optional, to track accuracy and other metrics)\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=f\"{evaluation_output_uri}/evaluation.json\",\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a model registration step with the diabetes model registry\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_artifact_path,\n",
    "    role=role,  # Replace with your actual role ARN\n",
    "    sagemaker_session=pipeline_session  # Attach the pipeline session here\n",
    ")\n",
    "\n",
    "register_args = model.register(\n",
    "    content_types=[\"application/x-model\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=\"diabetes\",  # Specify the model group name here\n",
    "    model_metrics=model_metrics  # Optional: Attach model metrics\n",
    ")\n",
    "step_register = ModelStep(name=\"diabetes\", step_args=register_args)\n",
    "\n",
    "\n",
    "# Define the condition to check accuracy\n",
    "cond_gte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"accuracy\"\n",
    "    ),\n",
    "    right=0.60\n",
    ")\n",
    "\n",
    "# Create a condition step\n",
    "condition_step = ConditionStep(\n",
    "    name=\"CheckAccuracy\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_register],  # Register the model if accuracy > 60%\n",
    "    else_steps=[]  # Do nothing if the accuracy is <= 60%\n",
    ")\n",
    "\n",
    "train_step.add_depends_on([processing_step])\n",
    "evaluation_step.add_depends_on([train_step])\n",
    "condition_step.add_depends_on([evaluation_step])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=\"testing-1\",\n",
    "    steps=[processing_step, train_step, evaluation_step, condition_step],\n",
    "    sagemaker_session=pipeline_session,  # Ensure the session is passed here\n",
    ")\n",
    "\n",
    "# Create and start the pipeline using SageMaker client\n",
    "pipeline.create(role_arn=role)  # Replace with your actual role ARN\n",
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b303268f-544e-4694-8cc1-0c631d625ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2025-12-13-09-27-18-721\n",
      "INFO:sagemaker:Creating endpoint-config with name diabetes-endpoint\n",
      "INFO:sagemaker:Creating endpoint with name diabetes-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!Deployed endpoint: diabetes-endpoint\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import Session\n",
    "\n",
    "sess = Session()\n",
    "role = role\n",
    "model_data = \"s3://main-sagemaker-ml-healthcare/mlops/output/pipelines-lr7i9qksuvkz-TrainModel-jHf9gQLIPs/output/model.tar.gz\"   # existing tar.gz\n",
    "entry_point = \"inference.py\"                       # local file\n",
    "\n",
    "sk_model = SKLearnModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point=entry_point,\n",
    "    framework_version=\"0.23-1\",\n",
    "    py_version=\"py3\",\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "endpoint_name = \"diabetes-endpoint\"\n",
    "predictor = sk_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",   # or smaller if quota issues\n",
    "    endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "print(\"Deployed endpoint:\", predictor.endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec45548-db72-42c0-8fba-1e6a58874db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker-runtime\", region_name=\"ap-south-1\")\n",
    "\n",
    "payload = \"1,148,41,33.6,0.345,60\"\n",
    "\n",
    "res = client.invoke_endpoint(\n",
    "    EndpointName=\"diabetes-endpoint\",\n",
    "    Body=payload,\n",
    "    ContentType=\"text/csv\",\n",
    "    Accept=\"text/csv\"\n",
    ")\n",
    "\n",
    "print(res['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d1a92-2539-40e1-aab1-6a426ebed6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......."
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import (\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    ")\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# SKLearn Estimator\n",
    "estimator = SKLearn(\n",
    "    entry_point=\"hyperparameter.py\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    hyperparameters={\n",
    "        \"min_samples_split\": 2\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define hyperparameter ranges to tune\n",
    "hyperparameter_ranges = {\n",
    "    \"n_estimators\": IntegerParameter(50, 300),\n",
    "    \"max_depth\": IntegerParameter(3, 15),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"Accuracy\"\n",
    "metric_definitions = [{\"Name\": \"Accuracy\", \"Regex\": \"Accuracy: (.*)\"}]\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=5,         # total training jobs\n",
    "    max_parallel_jobs=1 # run these many jobs in parallel\n",
    ")\n",
    "\n",
    "# Launch HPO job\n",
    "tuner.fit({\"train\": \"s3://main-sagemaker-ml-healthcare/mlops/train/\"})\n",
    "\n",
    "print(\"Hyperparameter tuning job started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440252a-54d1-4742-a0bc-04188b1b19bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8975e-0fb7-47a3-b7a0-04a812ddb7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
